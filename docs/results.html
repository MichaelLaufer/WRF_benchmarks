<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<!-- 2018-07-17 Tue 09:58 -->
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>Weather Research and Forecast (WRF) Scaling, Performance Assessment and Optimization</title>
<meta name="generator" content="Org mode" />
<meta name="author" content="Akira Kyle" />
<style type="text/css">
 <!--/*--><![CDATA[/*><!--*/
  .title  { text-align: center;
             margin-bottom: .2em; }
  .subtitle { text-align: center;
              font-size: medium;
              font-weight: bold;
              margin-top:0; }
  .todo   { font-family: monospace; color: red; }
  .done   { font-family: monospace; color: green; }
  .priority { font-family: monospace; color: orange; }
  .tag    { background-color: #eee; font-family: monospace;
            padding: 2px; font-size: 80%; font-weight: normal; }
  .timestamp { color: #bebebe; }
  .timestamp-kwd { color: #5f9ea0; }
  .org-right  { margin-left: auto; margin-right: 0px;  text-align: right; }
  .org-left   { margin-left: 0px;  margin-right: auto; text-align: left; }
  .org-center { margin-left: auto; margin-right: auto; text-align: center; }
  .underline { text-decoration: underline; }
  #postamble p, #preamble p { font-size: 90%; margin: .2em; }
  p.verse { margin-left: 3%; }
  pre {
    border: 1px solid #ccc;
    box-shadow: 3px 3px 3px #eee;
    padding: 8pt;
    font-family: monospace;
    overflow: auto;
    margin: 1.2em;
  }
  pre.src {
    position: relative;
    overflow: visible;
    padding-top: 1.2em;
  }
  pre.src:before {
    display: none;
    position: absolute;
    background-color: white;
    top: -10px;
    right: 10px;
    padding: 3px;
    border: 1px solid black;
  }
  pre.src:hover:before { display: inline;}
  /* Languages per Org manual */
  pre.src-asymptote:before { content: 'Asymptote'; }
  pre.src-awk:before { content: 'Awk'; }
  pre.src-C:before { content: 'C'; }
  /* pre.src-C++ doesn't work in CSS */
  pre.src-clojure:before { content: 'Clojure'; }
  pre.src-css:before { content: 'CSS'; }
  pre.src-D:before { content: 'D'; }
  pre.src-ditaa:before { content: 'ditaa'; }
  pre.src-dot:before { content: 'Graphviz'; }
  pre.src-calc:before { content: 'Emacs Calc'; }
  pre.src-emacs-lisp:before { content: 'Emacs Lisp'; }
  pre.src-fortran:before { content: 'Fortran'; }
  pre.src-gnuplot:before { content: 'gnuplot'; }
  pre.src-haskell:before { content: 'Haskell'; }
  pre.src-hledger:before { content: 'hledger'; }
  pre.src-java:before { content: 'Java'; }
  pre.src-js:before { content: 'Javascript'; }
  pre.src-latex:before { content: 'LaTeX'; }
  pre.src-ledger:before { content: 'Ledger'; }
  pre.src-lisp:before { content: 'Lisp'; }
  pre.src-lilypond:before { content: 'Lilypond'; }
  pre.src-lua:before { content: 'Lua'; }
  pre.src-matlab:before { content: 'MATLAB'; }
  pre.src-mscgen:before { content: 'Mscgen'; }
  pre.src-ocaml:before { content: 'Objective Caml'; }
  pre.src-octave:before { content: 'Octave'; }
  pre.src-org:before { content: 'Org mode'; }
  pre.src-oz:before { content: 'OZ'; }
  pre.src-plantuml:before { content: 'Plantuml'; }
  pre.src-processing:before { content: 'Processing.js'; }
  pre.src-python:before { content: 'Python'; }
  pre.src-R:before { content: 'R'; }
  pre.src-ruby:before { content: 'Ruby'; }
  pre.src-sass:before { content: 'Sass'; }
  pre.src-scheme:before { content: 'Scheme'; }
  pre.src-screen:before { content: 'Gnu Screen'; }
  pre.src-sed:before { content: 'Sed'; }
  pre.src-sh:before { content: 'shell'; }
  pre.src-sql:before { content: 'SQL'; }
  pre.src-sqlite:before { content: 'SQLite'; }
  /* additional languages in org.el's org-babel-load-languages alist */
  pre.src-forth:before { content: 'Forth'; }
  pre.src-io:before { content: 'IO'; }
  pre.src-J:before { content: 'J'; }
  pre.src-makefile:before { content: 'Makefile'; }
  pre.src-maxima:before { content: 'Maxima'; }
  pre.src-perl:before { content: 'Perl'; }
  pre.src-picolisp:before { content: 'Pico Lisp'; }
  pre.src-scala:before { content: 'Scala'; }
  pre.src-shell:before { content: 'Shell Script'; }
  pre.src-ebnf2ps:before { content: 'ebfn2ps'; }
  /* additional language identifiers per "defun org-babel-execute"
       in ob-*.el */
  pre.src-cpp:before  { content: 'C++'; }
  pre.src-abc:before  { content: 'ABC'; }
  pre.src-coq:before  { content: 'Coq'; }
  pre.src-groovy:before  { content: 'Groovy'; }
  /* additional language identifiers from org-babel-shell-names in
     ob-shell.el: ob-shell is the only babel language using a lambda to put
     the execution function name together. */
  pre.src-bash:before  { content: 'bash'; }
  pre.src-csh:before  { content: 'csh'; }
  pre.src-ash:before  { content: 'ash'; }
  pre.src-dash:before  { content: 'dash'; }
  pre.src-ksh:before  { content: 'ksh'; }
  pre.src-mksh:before  { content: 'mksh'; }
  pre.src-posh:before  { content: 'posh'; }
  /* Additional Emacs modes also supported by the LaTeX listings package */
  pre.src-ada:before { content: 'Ada'; }
  pre.src-asm:before { content: 'Assembler'; }
  pre.src-caml:before { content: 'Caml'; }
  pre.src-delphi:before { content: 'Delphi'; }
  pre.src-html:before { content: 'HTML'; }
  pre.src-idl:before { content: 'IDL'; }
  pre.src-mercury:before { content: 'Mercury'; }
  pre.src-metapost:before { content: 'MetaPost'; }
  pre.src-modula-2:before { content: 'Modula-2'; }
  pre.src-pascal:before { content: 'Pascal'; }
  pre.src-ps:before { content: 'PostScript'; }
  pre.src-prolog:before { content: 'Prolog'; }
  pre.src-simula:before { content: 'Simula'; }
  pre.src-tcl:before { content: 'tcl'; }
  pre.src-tex:before { content: 'TeX'; }
  pre.src-plain-tex:before { content: 'Plain TeX'; }
  pre.src-verilog:before { content: 'Verilog'; }
  pre.src-vhdl:before { content: 'VHDL'; }
  pre.src-xml:before { content: 'XML'; }
  pre.src-nxml:before { content: 'XML'; }
  /* add a generic configuration mode; LaTeX export needs an additional
     (add-to-list 'org-latex-listings-langs '(conf " ")) in .emacs */
  pre.src-conf:before { content: 'Configuration File'; }

  table { border-collapse:collapse; }
  caption.t-above { caption-side: top; }
  caption.t-bottom { caption-side: bottom; }
  td, th { vertical-align:top;  }
  th.org-right  { text-align: center;  }
  th.org-left   { text-align: center;   }
  th.org-center { text-align: center; }
  td.org-right  { text-align: right;  }
  td.org-left   { text-align: left;   }
  td.org-center { text-align: center; }
  dt { font-weight: bold; }
  .footpara { display: inline; }
  .footdef  { margin-bottom: 1em; }
  .figure { padding: 1em; }
  .figure p { text-align: center; }
  .inlinetask {
    padding: 10px;
    border: 2px solid gray;
    margin: 10px;
    background: #ffffcc;
  }
  #org-div-home-and-up
   { text-align: right; font-size: 70%; white-space: nowrap; }
  textarea { overflow-x: auto; }
  .linenr { font-size: smaller }
  .code-highlighted { background-color: #ffff00; }
  .org-info-js_info-navigation { border-style: none; }
  #org-info-js_console-label
    { font-size: 10px; font-weight: bold; white-space: nowrap; }
  .org-info-js_search-highlight
    { background-color: #ffff00; color: #000000; font-weight: bold; }
  .org-svg { width: 90%; }
  /*]]>*/-->
</style>
<link rel="stylesheet" type="text/css" href="styles/readtheorg/css/htmlize.css"/>
<link rel="stylesheet" type="text/css" href="styles/readtheorg/css/readtheorg.css"/>
<script src="https://ajax.googleapis.com/ajax/libs/jquery/2.1.3/jquery.min.js"></script>
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.4/js/bootstrap.min.js"></script>
<script type="text/javascript" src="styles/lib/js/jquery.stickytableheaders.min.js"></script>
<script type="text/javascript" src="styles/readtheorg/js/readtheorg.js"></script>
<script type="text/javascript">
/*
@licstart  The following is the entire license notice for the
JavaScript code in this tag.

Copyright (C) 2012-2018 Free Software Foundation, Inc.

The JavaScript code in this tag is free software: you can
redistribute it and/or modify it under the terms of the GNU
General Public License (GNU GPL) as published by the Free Software
Foundation, either version 3 of the License, or (at your option)
any later version.  The code is distributed WITHOUT ANY WARRANTY;
without even the implied warranty of MERCHANTABILITY or FITNESS
FOR A PARTICULAR PURPOSE.  See the GNU GPL for more details.

As additional permission under GNU GPL version 3 section 7, you
may distribute non-source (e.g., minimized or compacted) forms of
that code without the copy of the GNU GPL normally required by
section 4, provided you include this license notice and a URL
through which recipients can access the Corresponding Source.


@licend  The above is the entire license notice
for the JavaScript code in this tag.
*/
<!--/*--><![CDATA[/*><!--*/
 function CodeHighlightOn(elem, id)
 {
   var target = document.getElementById(id);
   if(null != target) {
     elem.cacheClassElem = elem.className;
     elem.cacheClassTarget = target.className;
     target.className = "code-highlighted";
     elem.className   = "code-highlighted";
   }
 }
 function CodeHighlightOff(elem, id)
 {
   var target = document.getElementById(id);
   if(elem.cacheClassElem)
     elem.className = elem.cacheClassElem;
   if(elem.cacheClassTarget)
     target.className = elem.cacheClassTarget;
 }
/*]]>*///-->
</script>
</head>
<body>
<div id="content">
<h1 class="title">Weather Research and Forecast (WRF) Scaling, Performance Assessment and Optimization
<br />
<span class="subtitle">NCAR SIParCS Program</span>
</h1>
<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="#org28b9d0b">Background</a>
<ul>
<li><a href="#orgce72050">The Weather Research and Forecast Model</a></li>
<li><a href="#org4f08d59">WRF Flowchart</a></li>
</ul>
</li>
<li><a href="#org219c153">Intro</a>
<ul>
<li><a href="#org14b7a2a">Test cases</a></li>
<li><a href="#org44ee19d">Compilers and MPI Libraries</a></li>
</ul>
</li>
<li><a href="#org280d1e5">Observations</a>
<ul>
<li><a href="#orgf4e7b2f">Compilation issue with gnu &gt; 6.3.0 and WRF &lt; V4.0</a></li>
<li><a href="#orgaa7c52c"><code>new_conus12km</code> on WRFV4.0 exceeds minimum patch size on &gt;= 32 nodes (36 cpus per node)</a></li>
<li><a href="#orgcb2cd28">Not enough memory for small node count on large cases</a></li>
<li><a href="#org8516cd4">Intel takes ~2x as long to compile wrf then gnu</a></li>
<li><a href="#org7d33640">WRF compilation option 66/67</a></li>
<li><a href="#orge2cb0cb">Jobs with over 10000 mpi tasks</a></li>
</ul>
</li>
<li><a href="#org3e04440">Results</a>
<ul>
<li><a href="#orga3ceb67">CONUS 12km</a></li>
<li><a href="#org4beeac1">NEW CONUS 12km WRFV3.8.1</a></li>
<li><a href="#org498941a">OLD CONUS 12km vs NEW CONUS 12km WRFV3.8.1</a></li>
<li><a href="#orgfc44785">NEW CONUS 12km</a></li>
<li><a href="#org888a8dd">NEW CONUS 2.5km</a></li>
<li><a href="#org1e9f9f2">Maria 3km</a></li>
<li><a href="#orgc4561a2">Cases</a></li>
<li><a href="#org48369e4">MPIs</a></li>
<li><a href="#org2788117">Compilers</a></li>
<li><a href="#org54cb82b">Hybrid</a></li>
</ul>
</li>
<li><a href="#orgd6931c0">WRF scaling and timing on Cheyenne</a>
<ul>
<li><a href="#org06f6638"><span class="todo TODO">TODO</span> Scaling Results</a>
<ul>
<li><a href="#org8ba8e69">old text</a></li>
</ul>
</li>
<li><a href="#org3d60c9f"><span class="todo TODO">TODO</span> Run time results</a></li>
</ul>
</li>
<li><a href="#orge21be8d"><span class="todo TODO">TODO</span> Optimizing WRF performance</a>
<ul>
<li><a href="#org6f6be31">Compiling and linking</a></li>
<li><a href="#org952b1af"><span class="todo TODO">TODO</span> Runtime options</a></li>
<li><a href="#orge348b88">Scaling and core count</a></li>
</ul>
</li>
<li><a href="#org4b70791">Summary</a>
<ul>
<li><a href="#org42b60d4">Conclusions</a></li>
</ul>
</li>
</ul>
</div>
</div>
<div class="warning">
<p>
This is still very much a work in progress!
</p>

</div>

<div id="outline-container-org28b9d0b" class="outline-2">
<h2 id="org28b9d0b">Background</h2>
<div class="outline-text-2" id="text-org28b9d0b">
</div>
<div id="outline-container-orgce72050" class="outline-3">
<h3 id="orgce72050">The Weather Research and Forecast Model</h3>
<div class="outline-text-3" id="text-orgce72050">
<p>
&ldquo;WRF is a state-of-the-art atmospheric modeling system designed for both
meteorological research and numerical weather prediction. It offers a host of
options for atmospheric processes and can run on a variety of computing
platforms. WRF excels in a broad range of applications across scales ranging
from tens of meters to thousands of kilometers, including the following.&rdquo;
</p>

<p>
– Meteorological studies
</p>
<p>
– Real-time NWP
</p>
<p>
– Idealized simulations
</p>
<p>
– Data assimilation
</p>
<p>
– Earth system model coupling
</p>
<p>
– Model training and educational support
</p>
</div>
</div>

<div id="outline-container-org4f08d59" class="outline-3">
<h3 id="org4f08d59">WRF Flowchart</h3>
<div class="outline-text-3" id="text-org4f08d59">

<div class="figure">
<p><img src="./figs/WRF_flow_chart-ARW_v4.png" alt="WRF_flow_chart-ARW_v4.png" />
</p>
</div>
</div>
</div>
</div>

<div id="outline-container-org219c153" class="outline-2">
<h2 id="org219c153">Intro</h2>
<div class="outline-text-2" id="text-org219c153">
</div>
<div id="outline-container-org14b7a2a" class="outline-3">
<h3 id="org14b7a2a">Test cases</h3>
<div class="outline-text-3" id="text-org14b7a2a">
<ul class="org-ul">
<li><code>conus12km</code> and <code>conus2.5km</code>
<ul class="org-ul">
<li>Official CONUS benchmarks from <a href="http://www2.mmm.ucar.edu/wrf/WG2/benchv3/">http://www2.mmm.ucar.edu/wrf/WG2/benchv3/</a></li>
<li>Benchmarks no longer maintained</li>
<li>Only works on WRFV3.8.1 or earlier</li>
<li><code>wrfbdy</code> generated using WRFV2.2 and <code>wrfrst</code> generated using WRFV3.2beta
provided</li>
</ul></li>
<li><code>katrina1km</code> <code>katrina3km</code>
<ul class="org-ul">
<li>cases based upon Katrina single domain case in WRF-ARW online tutorial
(<a href="http://www2.mmm.ucar.edu/wrf/OnLineTutorial/CASES/SingleDomain/index.html">http://www2.mmm.ucar.edu/wrf/OnLineTutorial/CASES/SingleDomain/index.html</a>)</li>
<li>Same domain and similar physics but higher resolution</li>
<li>cfl errors encountered often, especially with <code>1km</code> resolution
<ul class="org-ul">
<li>Mostly likely due to high vertical winds over mountain ranges in Mexico</li>
</ul></li>
</ul></li>
<li><code>new_conus12km</code> and <code>new_conus2.5km</code>
<ul class="org-ul">
<li>Based on official CONUS benchmarks</li>
<li>12km and 2.5km vertical and horizontal resolution respectively</li>
<li>Use CONUS Physics suite introduced in WRFV3.9 instead of physics used in
above official CONUS benchmarks</li>
<li><code>cu_physics = 0</code> for <code>new_conus2.5</code></li>
<li>NCEP GFS 0.25 deg input data for 2018-06-17</li>
<li>6 hour run, model output at 0, 3, 6hrs, restart file at 6hrs</li>
</ul></li>
<li><code>maria3km</code> and <code>maria1km</code>
<ul class="org-ul">
<li>3km and 1km vertical and horizontal resolution respectively</li>
<li>TROPICAL Physics suite with <code>cu_physics</code> disabled and <code>sf_sfclay_physics = 1</code></li>
</ul></li>
</ul>

<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="org-left" />

<col  class="org-right" />

<col  class="org-right" />

<col  class="org-left" />

<col  class="org-right" />

<col  class="org-right" />
</colgroup>
<thead>
<tr>
<th scope="col" class="org-left">case</th>
<th scope="col" class="org-right">e<sub>we</sub></th>
<th scope="col" class="org-right">e<sub>sn</sub></th>
<th scope="col" class="org-left">total gridpoints</th>
<th scope="col" class="org-right">timestep</th>
<th scope="col" class="org-right">run hours</th>
</tr>
</thead>
<tbody>
<tr>
<td class="org-left"><code>conus12km</code></td>
<td class="org-right">425</td>
<td class="org-right">300</td>
<td class="org-left">127,500</td>
<td class="org-right">72</td>
<td class="org-right">3</td>
</tr>

<tr>
<td class="org-left"><code>conus2.5km</code></td>
<td class="org-right">1901</td>
<td class="org-right">1301</td>
<td class="org-left">2,473,201</td>
<td class="org-right">15</td>
<td class="org-right">6</td>
</tr>

<tr>
<td class="org-left"><code>new_conus12km</code></td>
<td class="org-right">425</td>
<td class="org-right">300</td>
<td class="org-left">127,500</td>
<td class="org-right">72</td>
<td class="org-right">6</td>
</tr>

<tr>
<td class="org-left"><code>new_conus2.5km</code></td>
<td class="org-right">1901</td>
<td class="org-right">1301</td>
<td class="org-left">2,473,201</td>
<td class="org-right">15</td>
<td class="org-right">6</td>
</tr>

<tr>
<td class="org-left"><code>maria1km</code></td>
<td class="org-right">3665</td>
<td class="org-right">2894</td>
<td class="org-left">10,606,510</td>
<td class="org-right">3</td>
<td class="org-right">1</td>
</tr>

<tr>
<td class="org-left"><code>maria3km</code></td>
<td class="org-right">1396</td>
<td class="org-right">1384</td>
<td class="org-left">1,932,064</td>
<td class="org-right">9</td>
<td class="org-right">3</td>
</tr>
</tbody>
</table>
</div>
</div>

<div id="outline-container-org44ee19d" class="outline-3">
<h3 id="org44ee19d">Compilers and MPI Libraries</h3>
<div class="outline-text-3" id="text-org44ee19d">
<ul class="org-ul">
<li>GNU Compiler Collection (GCC) versions 6.3.0, 8.1.0
<ul class="org-ul">
<li>WRF compiles with <code>-O2</code> by default</li>
<li>Tried <code>-O3</code>, <code>-Ofast</code>, <code>-mfma</code> (enables FMA instruction set), <code>-march=native</code></li>
</ul></li>
<li>Intel Compiler versions 17.0.1, 18.0.1
<ul class="org-ul">
<li>WRF compiles with <code>-O3</code> by default</li>
<li>Tried <code>-Xhost</code> which is similar to GNU&rsquo;s <code>-march=native</code></li>
</ul></li>
<li>MPT version 2.18</li>
<li>MVAPICH version 2.2</li>
<li>openMPI version 3.1.0</li>
<li>Intel MPI version 2018.1.163</li>
<li>MPICH version 3.2</li>
</ul>
</div>
</div>
</div>

<div id="outline-container-org280d1e5" class="outline-2">
<h2 id="org280d1e5">Observations</h2>
<div class="outline-text-2" id="text-org280d1e5">
</div>
<div id="outline-container-orgf4e7b2f" class="outline-3">
<h3 id="orgf4e7b2f">Compilation issue with gnu &gt; 6.3.0 and WRF &lt; V4.0</h3>
<div class="outline-text-3" id="text-orgf4e7b2f">
<p>
This likely require a source patch to fix, not an environment or compiler issue
</p>
<pre class="example">
module_cu_g3.f90:3132:41:

                    call random_seed (PUT=seed)
                                         1
Error: Size of ‘put’ argument of ‘random_seed’ intrinsic at (1) too small (12/33)
</pre>
</div>
</div>

<div id="outline-container-orgaa7c52c" class="outline-3">
<h3 id="orgaa7c52c"><code>new_conus12km</code> on WRFV4.0 exceeds minimum patch size on &gt;= 32 nodes (36 cpus per node)</h3>
<div class="outline-text-3" id="text-orgaa7c52c">
<pre class="example">
taskid: 0 hostname: r14i1n17
 module_io_quilt_old.F        2931 F
Quilting with   1 groups of   0 I/O tasks.
 Ntasks in X           32 , ntasks in Y           36
*************************************
Configuring physics suite 'conus'

         mp_physics:      8
         cu_physics:      6
      ra_lw_physics:      4
      ra_sw_physics:      4
     bl_pbl_physics:      2
  sf_sfclay_physics:      2
 sf_surface_physics:      2
*************************************
   For domain            1 , the domain size is too small for this many processors, or the decomposition aspect ratio is poor.
   Minimum decomposed computational patch size, either x-dir or y-dir, is 10 grid cells.
  e_we =   425, nproc_x =   32, with cell width in x-direction =   13
  e_sn =   300, nproc_y =   36, with cell width in y-direction =    8
  --- ERROR: Reduce the MPI rank count, or redistribute the tasks.
-------------- FATAL CALLED ---------------
FATAL CALLED FROM FILE:  &lt;stdin&gt;  LINE:    1726
NOTE:       1 namelist settings are wrong. Please check and reset these options
-------------------------------------------
</pre>

<div class="note">
<p>
This is a change in WRFV4.0 from previous versions. From
<a href="http://www2.mmm.ucar.edu/wrf/users/wrfv4.0/updates-4.0.html">http://www2.mmm.ucar.edu/wrf/users/wrfv4.0/updates-4.0.html</a>:
</p>
<ul class="org-ul">
<li>&ldquo;Determine the resultant x- and y-direction computational patch sizes based
on the full domain size and the number of MPI ranks used in each direction. If
the patch size &lt; 10 grid cells in either direction, the model will stop.&rdquo;</li>
</ul>

</div>
</div>
</div>

<div id="outline-container-orgcb2cd28" class="outline-3">
<h3 id="orgcb2cd28">Not enough memory for small node count on large cases</h3>
<div class="outline-text-3" id="text-orgcb2cd28">
<p>
When run on cheyenne&rsquo;s 64 GB memory nodes
(<a href="https://www2.cisl.ucar.edu/resources/computational-systems/cheyenne">https://www2.cisl.ucar.edu/resources/computational-systems/cheyenne</a>), WRFV4.0
usually see jobs SIGKILLed at various points during startup for
</p>
<ul class="org-ul">
<li><code>new_conus2.5</code> on &lt;= 2 nodes</li>
<li><code>maria3km</code> on 1 node</li>
<li><code>maria1km</code> on &lt;= 8 nodes</li>
</ul>
</div>
</div>

<div id="outline-container-org8516cd4" class="outline-3">
<h3 id="org8516cd4">Intel takes ~2x as long to compile wrf then gnu</h3>
</div>
<div id="outline-container-org7d33640" class="outline-3">
<h3 id="org7d33640">WRF compilation option 66/67</h3>
<div class="outline-text-3" id="text-org7d33640">
<p>
Relevant diff of <code>configure.wrf</code>:
</p>
<pre class="example">
5c5
&lt; # Compiler choice: 15
---
&gt; # Compiler choice: 66
161,163c128,130
&lt; ARCH_LOCAL      =       -DNONSTANDARD_SYSTEM_FUNC  -DWRF_USE_CLM $(NETCDF4_IO_OPTS)
&lt; CFLAGS_LOCAL    =       -w -O3 -ip #-xHost -fp-model fast=2 -no-prec-div -no-prec-sqrt -ftz -no-multibyte-chars
&lt; LDFLAGS_LOCAL   =       -ip #-xHost -fp-model fast=2 -no-prec-div -no-prec-sqrt -ftz -align all -fno-alias -fno-common
---
&gt; ARCH_LOCAL      =       -DNONSTANDARD_SYSTEM_FUNC -DWRF_USE_CLM $(NETCDF4_IO_OPTS)
&gt; CFLAGS_LOCAL    =       -w -O3 -ip -xHost -fp-model fast=2 -no-prec-div -no-prec-sqrt -ftz -no-multibyte-chars -xCORE-AVX2
&gt; LDFLAGS_LOCAL   =       -ip -xHost -fp-model fast=2 -no-prec-div -no-prec-sqrt -ftz -align all -fno-alias -fno-common -xCORE-AVX2
175c142
&lt; FCBASEOPTS_NO_G =       -ip -fp-model precise -w -ftz -align all -fno-alias $(FORMAT_FREE) $(BYTESWAPIO) #-xHost -fp-model fast=2 -no-heap-arrays -no-prec-div -no-prec-sqrt -fno-common
---
&gt; FCBASEOPTS_NO_G =       -ip -fp-model precise -w -ftz -align all -fno-alias $(FORMAT_FREE) $(BYTESWAPIO) -xHost -fp-model fast=2 -no-heap-arrays -no-prec-div -no-prec-sqrt -fno-common -xCORE-AVX2
</pre>
</div>
</div>

<div id="outline-container-orge2cb0cb" class="outline-3">
<h3 id="orge2cb0cb">Jobs with over 10000 mpi tasks</h3>
<div class="outline-text-3" id="text-orge2cb0cb">
<p>
WRF produces <code>rsl.out.XXXX</code> and <code>rsl.error.XXXX</code> files for every mpi task, so to
support &gt; 10000 mpi tasks, one must patch WRF to have a longer rsl file number
format otherwise one may encounter the following error:
</p>
<pre class="example">
rsl_lite error ("buf_for_proc.c":119) Bad P argument to buffer_for_proc.  P = 18088. Has RSL_MESH been called?
</pre>
</div>
</div>
</div>

<div id="outline-container-org3e04440" class="outline-2">
<h2 id="org3e04440">Results</h2>
<div class="outline-text-2" id="text-org3e04440">
</div>
<div id="outline-container-orga3ceb67" class="outline-3">
<h3 id="orga3ceb67">CONUS 12km</h3>
<div class="outline-text-3" id="text-orga3ceb67">

<div class="figure">
<p><object type="image/svg+xml" data="./imgs/conus12km.svg" class="org-svg">
Sorry, your browser does not support SVG.</object>
</p>
</div>
</div>
</div>

<div id="outline-container-org4beeac1" class="outline-3">
<h3 id="org4beeac1">NEW CONUS 12km WRFV3.8.1</h3>
<div class="outline-text-3" id="text-org4beeac1">

<div class="figure">
<p><object type="image/svg+xml" data="./imgs/new_conus12km_3.svg" class="org-svg">
Sorry, your browser does not support SVG.</object>
</p>
</div>
</div>
</div>

<div id="outline-container-org498941a" class="outline-3">
<h3 id="org498941a">OLD CONUS 12km vs NEW CONUS 12km WRFV3.8.1</h3>
<div class="outline-text-3" id="text-org498941a">

<div class="figure">
<p><object type="image/svg+xml" data="./imgs/old_vs_new_conus12km_3.svg" class="org-svg">
Sorry, your browser does not support SVG.</object>
</p>
</div>
</div>
</div>

<div id="outline-container-orgfc44785" class="outline-3">
<h3 id="orgfc44785">NEW CONUS 12km</h3>
<div class="outline-text-3" id="text-orgfc44785">

<div class="figure">
<p><object type="image/svg+xml" data="./imgs/new_conus12km.svg" class="org-svg">
Sorry, your browser does not support SVG.</object>
</p>
</div>
</div>
</div>

<div id="outline-container-org888a8dd" class="outline-3">
<h3 id="org888a8dd">NEW CONUS 2.5km</h3>
<div class="outline-text-3" id="text-org888a8dd">

<div class="figure">
<p><object type="image/svg+xml" data="./imgs/new_conus2-5km.svg" class="org-svg">
Sorry, your browser does not support SVG.</object>
</p>
</div>
</div>
</div>

<div id="outline-container-org1e9f9f2" class="outline-3">
<h3 id="org1e9f9f2">Maria 3km</h3>
<div class="outline-text-3" id="text-org1e9f9f2">

<div class="figure">
<p><object type="image/svg+xml" data="./imgs/maria3km.svg" class="org-svg">
Sorry, your browser does not support SVG.</object>
</p>
</div>
</div>
</div>

<div id="outline-container-orgc4561a2" class="outline-3">
<h3 id="orgc4561a2">Cases</h3>
<div class="outline-text-3" id="text-orgc4561a2">

<div class="figure">
<p><object type="image/svg+xml" data="./imgs/cases.svg" class="org-svg">
Sorry, your browser does not support SVG.</object>
</p>
</div>
</div>
</div>

<div id="outline-container-org48369e4" class="outline-3">
<h3 id="org48369e4">MPIs</h3>
<div class="outline-text-3" id="text-org48369e4">

<div class="figure">
<p><object type="image/svg+xml" data="./imgs/new_conus12km_mpi.svg" class="org-svg">
Sorry, your browser does not support SVG.</object>
</p>
</div>


<div class="figure">
<p><object type="image/svg+xml" data="./imgs/new_conus2-5km_mpi.svg" class="org-svg">
Sorry, your browser does not support SVG.</object>
</p>
</div>


<div class="figure">
<p><object type="image/svg+xml" data="./imgs/new_conus12km_bar_normal.svg" class="org-svg">
Sorry, your browser does not support SVG.</object>
</p>
</div>


<div class="figure">
<p><object type="image/svg+xml" data="./imgs/new_conus12km_bar_large.svg" class="org-svg">
Sorry, your browser does not support SVG.</object>
</p>
</div>
</div>
</div>

<div id="outline-container-org2788117" class="outline-3">
<h3 id="org2788117">Compilers</h3>
<div class="outline-text-3" id="text-org2788117">

<div class="figure">
<p><object type="image/svg+xml" data="./imgs/new_conus12km_compiler.svg" class="org-svg">
Sorry, your browser does not support SVG.</object>
</p>
</div>


<div class="figure">
<p><object type="image/svg+xml" data="./imgs/new_conus2-5km_compiler.svg" class="org-svg">
Sorry, your browser does not support SVG.</object>
</p>
</div>


<div class="figure">
<p><object type="image/svg+xml" data="./imgs/new_conus12km_gnu.svg" class="org-svg">
Sorry, your browser does not support SVG.</object>
</p>
</div>


<div class="figure">
<p><object type="image/svg+xml" data="./imgs/new_conus12km_intel.svg" class="org-svg">
Sorry, your browser does not support SVG.</object>
</p>
</div>
</div>
</div>

<div id="outline-container-org54cb82b" class="outline-3">
<h3 id="org54cb82b">Hybrid</h3>
<div class="outline-text-3" id="text-org54cb82b">

<div class="figure">
<p><object type="image/svg+xml" data="./imgs/hybrid.svg" class="org-svg">
Sorry, your browser does not support SVG.</object>
</p>
</div>


<div class="figure">
<p><object type="image/svg+xml" data="./imgs/hybrid_bar_normal.svg" class="org-svg">
Sorry, your browser does not support SVG.</object>
</p>
</div>


<div class="figure">
<p><object type="image/svg+xml" data="./imgs/hybrid_bar_large.svg" class="org-svg">
Sorry, your browser does not support SVG.</object>
</p>
</div>
</div>
</div>
</div>

<div id="outline-container-orgd6931c0" class="outline-2">
<h2 id="orgd6931c0">WRF scaling and timing on Cheyenne<sup><a id="fnr.1" class="footref" href="#fn.1">1</a></sup></h2>
<div class="outline-text-2" id="text-orgd6931c0">
<ul class="org-ul">
<li>&ldquo;Is it possible to solve a problem with such-and-such resolution in a timely
manner?&rdquo;</li>
<li>&ldquo;If I use more cores I will have the results more quickly, but with this
resolution will my run be in the efficient strong-scaling regime, an
intermediate one, or in the very inefficient one dominated by I/O and
initialization instead of computing?&rdquo;</li>
</ul>

<p>
Numbers from the figures below can help you develop some back-of-the-envelope
estimates of what will happen if you increase or decrease the core counts of
your runs, so that you can find one that is optimal for you both in terms of
time-to-solution and in terms of your allocation.
</p>

<hr />
</div>

<div id="outline-container-org06f6638" class="outline-3">
<h3 id="org06f6638"><span class="todo TODO">TODO</span> Scaling Results</h3>
<div class="outline-text-3" id="text-org06f6638">
<p>
Figure <a href="#org13e2762">20</a> shows scaling results from Hurricane Maria simulations at 3km
and 1km resolutions along with CONUS simulations at 12km and 2.5km resolutions
all run using WRFV4.0. When expressed this way, all the cases scale similarly.
Note that both axes are logarithmic, so a small distance between points
corresponds to a large difference in values.
</p>


<div id="org13e2762" class="figure">
<p><object type="image/svg+xml" data="./imgs/cases.svg" class="org-svg">
Sorry, your browser does not support SVG.</object>
</p>
<p><span class="figure-number">Figure 20: </span>WRF scaling</p>
</div>




<p>
Beginning in WRFV4.0, the minimum patch size is 10 grid cells in either
direction. This limits you to using at least 100 gridpoints/core. Thus WRF will
prevent you from running on very large relative core counts where
initialization, I/O, and communication dominate.
</p>
</div>

<div id="outline-container-org8ba8e69" class="outline-4">
<h4 id="org8ba8e69">old text</h4>
<div class="outline-text-4" id="text-org8ba8e69">
<p>
As you can see, there are three regimes:
</p>

<ul class="org-ul">
<li>large number of grid points per core - <b>Total grid points / core &gt; 10<sup>5</sup></b>
(small core count)</li>
<li>intermediate number of grid points per core - <b>10<sup>4</sup> &lt; Total grid points / core
&lt; 10<sup>5</sup></b> (intermediate core count)</li>
<li>small number of grid points per core - <b>Total grid points / core &lt; 10<sup>4</sup></b>
(large core count)</li>
</ul>

<p>
For a small number of cores, the WRF computation kernel is in a strong scaling
regime. Increasing the core count will make the simulation go faster while it
consumes approximately the same amount of core-hours (ignoring time spent in
initialization and I/O). Time-to-solution will also depend on the wait in queue,
which may be larger for larger jobs.
</p>

<p>
For an intermediate number of cores, WRF scaling increasingly departs from
linear strong scaling. Running the same simulation on larger core counts will
require more core-hours even though it will still run faster (again, ignoring
time spent in initialization, I/O, and wait in queue).
</p>

<p>
We do not recommend running WRF on extremely large core counts, because in this
regime the speed benefits diminish, the time will be dominated by initialization
and I/O (as well as wait in queue), and there will be larger core-hours charges
for solving the same problem.
</p>
</div>
</div>
</div>

<div id="outline-container-org3d60c9f" class="outline-3">
<h3 id="org3d60c9f"><span class="todo TODO">TODO</span> Run time results</h3>
<div class="outline-text-3" id="text-org3d60c9f">
<p>
Figure <a href="#orga8c1ee3">1</a> below shows the total run time for WRF jobs using increasing
numbers of cores. Initialization time, computation time, and writing time also
are shown for runs using up to 9,216 cores.
</p>

<p>
These results are based on simulations of Hurricane Maria (2017) at 1km
resolution.
</p>

<p>
As illustrated, initialization and writing output times remain relatively fixed,
but increasing slightly as you move to larger core counts. Times shown are for a
and single output file of the Maria 1km case, which used a domain of about 372
million grid points. If you have more restarts and output files, your numbers
will be different but the trend will be similar.
</p>


<div class="figure">
<p><object type="image/svg+xml" data="./imgs/maria1km_runtime.svg" class="org-svg">
Sorry, your browser does not support SVG.</object>
</p>
</div>
</div>
</div>
</div>

<div id="outline-container-orge21be8d" class="outline-2">
<h2 id="orge21be8d"><span class="todo TODO">TODO</span> Optimizing WRF performance<sup><a id="fnr.2" class="footref" href="#fn.2">2</a></sup></h2>
<div class="outline-text-2" id="text-orge21be8d">
<p>
These recommendations for optimizing the performance of the Weather Research and
Forecasting (WRF) modeling system are based on the results of numerous jobs run
on the Cheyenne system by the CISL Consulting Services Group. The jobs
included small runs and others, with different domain sizes and time steps.
</p>

<hr />
</div>

<div id="outline-container-org6f6be31" class="outline-3">
<h3 id="org6f6be31">Compiling and linking</h3>
<div class="outline-text-3" id="text-org6f6be31">
<p>
We recommend using the default <b>Intel compiler</b>. In our runs, the Intel compiler
consistently outperformed the GNU compiler by ~1.5x.
</p>

<p>
and the compiler&rsquo;s default
settings as contained in the script for creating the <b>configure.wrf</b> file.
</p>

<p>
The best results were achieved with a <b>Distributed-Memory Parallelism (DMPar)</b>
build, which enables MPI. Depending on the individual case, advanced WRF users
may find some improvement in performance with a hybrid build, using both DMPar
and SMPar.
</p>

<p>
We do not recommend SMPar alone or serial WRF builds.
</p>

<hr />
</div>
</div>

<div id="outline-container-org952b1af" class="outline-3">
<h3 id="org952b1af"><span class="todo TODO">TODO</span> Runtime options</h3>
<div class="outline-text-3" id="text-org952b1af">
<p>
We recommend using the following when running WRF jobs:
</p>

<ol class="org-ol">
<li>Hyper-threading</li>
<li>Processor binding</li>
</ol>

<p>
Hyper-threading improved computing performance by 8% in a test MPI case using
256 Yellowstone nodes. In other cases, hyper-threading had negligible impact.
</p>

<p>
Tests of hybrid MPI/OpenMP jobs, both with and without hyper-threading, showed
that hybrid parallelism can provide marginally higher performance than pure MPI
parallelism, but run-to-run variability was high.
</p>

<p>
Processor binding was enabled by default when running MPI jobs on Yellowstone.
We used the default binding settings in test runs.
</p>

<hr />
</div>
</div>

<div id="outline-container-orge348b88" class="outline-3">
<h3 id="orge348b88">Scaling and core count</h3>
<div class="outline-text-3" id="text-orge348b88">
<p>
WRF is a highly scalable model, demonstrating both weak and strong scaling,
within limits defined by the problem size. We do not recommend running WRF on
extremely large core counts (relative to the number of grid points in the
domain). This is because there will be increasingly less speed benefit as
communication costs exceed the computational work per core. Extremely large core
counts for WRF are defined as those for which <b>cores &gt; total grid points/10<sup>4</sup></b>.
</p>

<p>
<b>Weak scaling</b>: When increasing both problem size and core count, the time to
solution remains constant provided that the core count is small enough that the
time spent in I/O and initialization remains negligible. When you increase the
size of the WRF domain, you can usually increase the core count to keep a
constant time to solution—provided that the time spent in I/O and initialization
remains negligible. You will need to run some tests with your own settings
(especially input files and I/O frequency and format) to determine the upper
limit for your core count.
</p>

<p>
<b>Strong scaling</b>: When running WRF on relatively small numbers of cores (<b>namely
cores &lt; total grid points/10<sup>5</sup></b>), the time to solution decreases in inverse
proportion to increases in core count if the problem size is unchanged. In such
a strong scaling regime, increasing only the core count has no performance
downside. We recommend making some runs to confirm that you are using the
optimal core count for your problem size.
</p>
</div>
</div>
</div>

<div id="outline-container-org4b70791" class="outline-2">
<h2 id="org4b70791">Summary</h2>
<div class="outline-text-2" id="text-org4b70791">
</div>
<div id="outline-container-org42b60d4" class="outline-3">
<h3 id="org42b60d4">Conclusions</h3>
<div class="outline-text-3" id="text-org42b60d4">
<ul class="org-ul">
<li>openMPI, MPT, and MVAPICH show similar runtime performance.</li>
<li>intel consistently faster than gnu</li>
</ul>
</div>
</div>
</div>
<div id="footnotes">
<h2 class="footnotes">Footnotes: </h2>
<div id="text-footnotes">

<div class="footdef"><sup><a id="fn.1" class="footnum" href="#fnr.1">1</a></sup> <div class="footpara"><a href="https://www2.cisl.ucar.edu/software/community-models/wrf-scaling-and-timing">On Yellowstone</a></div></div>

<div class="footdef"><sup><a id="fn.2" class="footnum" href="#fnr.2">2</a></sup> <div class="footpara"><a href="https://www2.cisl.ucar.edu/software/community-models/optimizing-wrf-performance">On Yellowstone</a></div></div>


</div>
</div></div>
<div id="postamble" class="status">
<p class="author">Author: Akira Kyle</p>
<p class="email">Email: <a href="mailto:akyle@cmu.edu">akyle@cmu.edu</a></p>
<p class="date">Created: 2018-07-17 Tue 09:58</p>
<p class="validation"><a href="http://validator.w3.org/check?uri=referer">Validate</a></p>
</div>
</body>
</html>
