#!/bin/bash
### Job Name
#PBS -N WRFV3.9.1.1-intel-dmpar-mpt2.18-conus12km
### Project code
#PBS -A SCSG0002
#PBS -l walltime=00:20:00
#PBS -q regular
### Merge output and error files
#PBS -j oe
### Select 2 nodes with 36 CPUs each for a total of 72 MPI processes
#PBS -l select=2:ncpus=36:mpiprocs=36
### Send email on abort, begin and end
#PBS -m abe
### Specify mail recipient
#PBS -M akirak@ucar.edu

export TMPDIR=/glade/scratch/$USER/temp
mkdir -p $TMPDIR

RUN_DIR=~/work/run/conus12km/WRFV3.9.1.1-intel-dmpar-mpt2.18/2nodes
mkdir -p $RUN_DIR
cd $RUN_DIR

# link the necessary files into the run directory
WG2BENCH_DIR=~/WG2bench/conus12km_v3-2
ln -sf $WG2BENCH_DIR/namelist.input .
ln -sf $WG2BENCH_DIR/wrfbdy_d01 .
ln -sf $WG2BENCH_DIR/wrfrst_d01_2001-10-24_03_00_00 .

wrf_link ~/work/WRFs/WRFV3.9.1.1-intel-dmpar-mpt2.18

### Run the executable
mpiexec_mpt ./wrf.exe

