* Benchmarks for WRF
This repo documents the benchmark cases used for assessing the scaling
performance of WRF on NCAR's Cheyenne Supercomputer.

- ~namelists/~ contains the namelists for WPS and WRF for the various benchmark
  cases.
- ~scripts/~ contains useful scripts for automating the compilation, running,
  and analysis of the WRF test cases
- ~results/~ contains the timing results and analysis and plotting code
- ~privatemodules/mvapich~ contains a custom module for mvapich since cheyenne
  currently does not have an mvapich module. See ~.profile~ for adding this
  custom module to your environment.

** WRF compilation
~wrf_compile~ will compile WRF from source with the given options. See
~wrf_compile --help~

For both WRF3.9.1.1 and WRFV3.8.1:
- compiler option 15 = dmpar - INTEL (ifort/icc)
- nest option 1 = basic

Example invocations of ~wrf_compile~ on cheyenne:

#+begin_src sh
wrf_compile \
    --source ~wrfhelp/SOURCE_CODE/WRFV3.9.1.1.TAR.gz\
    --wrfdir ~/work/WRFs/WRFV3.9.1.1-intel-serial \
    --compile 13 \
    --nest 1 \
    --modules \
    ncarenv/1.2 \
    intel/18.0.1 \
    ncarcompilers/0.4.1 \
    netcdf/4.6.0
#+end_src

#+begin_src sh
wrf_compile \
    --source ~wrfhelp/SOURCE_CODE/WRFV3.9.1.1.TAR.gz\
    --wrfdir ~/work/WRFs/WRFV3.9.1.1-intel-dmpar-mpt2.18 \
    --compile 15 \
    --nest 1 \
    --mpiexec mpiexec_mpt \
    --modules \
    ncarenv/1.2 \
    intel/18.0.1 \
    ncarcompilers/0.4.1 \
    mpt/2.18 \
    netcdf/4.6.0
#+end_src

#+begin_src sh
wrf_compile \
    --source ~wrfhelp/SOURCE_CODE/WRFV3.8.1.TAR.gz\
    --wrfdir ~/work/WRFs/WRFV3.8.1-intel-dmpar-mpt2.18 \
    --compile 15 \
    --nest 1 \
    --mpiexec mpiexec_mpt \
    --modules \
    ncarenv/1.2 \
    intel/18.0.1 \
    ncarcompilers/0.4.1 \
    mpt/2.18 \
    netcdf/4.6.0
#+end_src

#+begin_src sh
wrf_compile \
    --source ~wrfhelp/SOURCE_CODE/WRFV3.8.1.TAR.gz\
    --wrfdir ~/work/WRFs/WRFV3.8.1-gnu6.3.0-mpt2.18 \
    --compile 34 \
    --nest 1 \
    --mpiexec mpiexec_mpt \
    --modules \
    ncarenv/1.2 \
    gnu/6.3.0 \
    ncarcompilers/0.4.1 \
    mpt/2.18 \
    netcdf/4.6.1
#+end_src

#+begin_src sh
wrf_compile \
    --source ~wrfhelp/SOURCE_CODE/WRFV3.8.1.TAR.gz\
    --wrfdir ~/work/WRFs/WRFV3.8.1-gnu7.3.0-mpt2.18 \
    --compile 34 \
    --nest 1 \
    --mpiexec mpiexec_mpt \
    --modules \
    ncarenv/1.2 \
    gnu/7.3.0 \
    ncarcompilers/0.4.1 \
    mpt/2.18 \
    netcdf/4.6.1
#+end_src

#+begin_src sh
wrf_compile \
    --source ~wrfhelp/SOURCE_CODE/WRFV3.8.1.TAR.gz\
    --wrfdir ~/work/WRFs/WRFV3.8.1-gnu-dmpar-mvapich2.2 \
    --compile 34 \
    --nest 1 \
    --mpiexec 'mpirun_rsh -hostfile $PBS_NODEFILE -n $1'  \
    --modules \
    ncarenv/1.2 \
    gnu/6.3.0 \
    ncarcompilers/0.4.1 \
    mvapich/2.2 \
    netcdf/4.6.1
#+end_src

#+begin_src sh
wrf_compile \
    --source ~wrfhelp/SOURCE_CODE/WRFV3.8.1.TAR.gz\
    --wrfdir ~/work/WRFs/WRFV3.8.1-gnu6.3.0-mvapich2.2 \
    --compile 34 \
    --nest 1 \
    --mpiexec 'mpirun_rsh -hostfile $PBS_NODEFILE -n $1'  \
    --modules \
    ncarenv/1.2 \
    gnu/6.3.0 \
    ncarcompilers/0.4.1 \
    mvapich2/2.2 \
    netcdf/4.6.1
#+end_src

#+begin_src sh
wrf_compile \
    --source ~wrfhelp/SOURCE_CODE/WRFV3.7.1.TAR.gz\
    --wrfdir ~/work/WRFs/WRFV3.7.1-intel-dmpar-mpt2.18 \
    --compile 15 \
    --nest 1 \
    --mpiexec mpiexec_mpt \
    --modules \
    ncarenv/1.2 \
    intel/18.0.1 \
    ncarcompilers/0.4.1 \
    mpt/2.18 \
    netcdf/4.6.0
#+end_src

#+begin_src sh
wrf_compile \
    --source ~wrfhelp/SOURCE_CODE/WRFV3.6.1.TAR.gz\
    --wrfdir ~/work/WRFs/WRFV3.6.1-intel-dmpar-mpt2.18 \
    --compile 15 \
    --nest 1 \
    --mpiexec mpiexec_mpt \
    --modules \
    ncarenv/1.2 \
    intel/18.0.1 \
    ncarcompilers/0.4.1 \
    mpt/2.18 \
    netcdf/4.6.0
#+end_src

** Example pbs job scripts for cheyenne
#+begin_src sh
#!/bin/bash
### Job Name
#PBS -N cheyenne_wrf
### Project code
#PBS -A SCSG0002
#PBS -l walltime=00:20:00
#PBS -q regular
### Merge output and error files
#PBS -j oe
### Select 2 nodes with 36 CPUs each for a total of 72 MPI processes
#PBS -l select=2:ncpus=36:mpiprocs=36
### Send email on abort, begin and end
#PBS -m abe
### Specify mail recipient
#PBS -M akirak@ucar.edu

export TMPDIR=/glade/scratch/$USER/temp
mkdir -p $TMPDIR

### Run the executable
mpiexec_mpt ./wrf.exe
#+end_src

~real.exe~ must also be run with mpi
#+begin_src sh
mpiexec_mpt ./real.exe
#+end_src

To profile with ~arm-map~
#+begin_src sh
module load arm-forge/18.1.2
# map --connect ./wrf.exe # for live, interactive profiling
map --profile ./wrf.exe # for generating profile file to be loaded later
#+end_src

To profile with ~arm-reports~
#+begin_src sh
module load arm-reports/18.1.2
perf-report -mpi -n 72 ./wrf.exe
#+end_src

To use ~mvapich~ instead of ~mpt~
#+begin_src sh
ml reset
ml rm mpt/2.15f

export PATH=/glade/u/apps/ch/opt/mvapich2/2.2/gnu/7.1.0/bin/:$PATH

mpirun_rsh -hostfile $PBS_NODEFILE -n 72 ./wrf.exe
#+end_src


** Batch PBS job scripts generation and submission
~wrf_run_pbs_jobs~ will create the run directories and pbs job scripts necessary
to run the given WRF versions with the given node counts and benchmark cases.
See ~wrf_run_pbs_jobs --help~.

Example invocations of ~wrf_run_pbs_jobs~:
#+begin_src sh
wrf_run_pbs_jobs -w WRFs/WRFV3.9.1.1-intel-dmpar-mpt2.18 -n 2 -c cases/conus12km -t 1
wrf_run_pbs_jobs -w WRFs/WRFV3.8.1-intel-dmpar-mpt2.18 -n 2 -c cases/conus12km -t 1
wrf_run_pbs_jobs -w WRFs/WRFV3.8.1-gnu-dmpar-mvapich2.2 -n 2 -c cases/conus12km -t 1
wrf_run_pbs_jobs -w WRFs/WRFV3.8.1-intel-dmpar-mpt2.18 -n 2 -c cases/conus2.5km -t 1
wrf_run_pbs_jobs -w WRFs/WRFV3.9.1.1-intel-dmpar-mpt2.18 -n 2 -c cases/conus2.5km -t 1
wrf_run_pbs_jobs -w WRFs/WRFV3.7.1-intel-dmpar-mpt2.18 -n 2 -c cases/conus2.5km -t 1
wrf_run_pbs_jobs -w WRFs/WRFV3.9.1.1-intel-dmpar-mpt2.18 -n 2 -c cases/katrina-ex -t 1
wrf_run_pbs_jobs -w WRFs/WRFV3.9.1.1-intel-dmpar-mpt2.18 -n 8 -c cases/katrina1km -t 1
wrf_run_pbs_jobs -w WRFs/WRFV3.9.1.1-intel-dmpar-mpt2.18 -n 2 -c cases/katrina3km -t 2 -a '01:00:00'
wrf_run_pbs_jobs -w WRFs/WRFV3.9.1.1-intel-dmpar-mpt2.18 -n 2 -c cases/katrina1km -t 2 -a '02:00:00'
wrf_run_pbs_jobs -w WRFs/WRFV3.9.1.1-intel-dmpar-mpt2.18 -n 12 -c cases/katrina1km -t 1 -a '02:00:00'
#+end_src

#+begin_src sh
wrf_run_pbs_jobs \
    --wrfs ~/work/WRFs/WRFV3.8.1-gnu-dmpar-mvapich2.2 \
    --nodes 1 2 4 8 16 32 64 \
    --cases ~/WRF_benchmarks/cases/conus12km \
    --trial 1
wrf_run_pbs_jobs \
    --wrfs ~/work/WRFs/WRFV3.8.1-intel-dmpar-mpt2.18 \
    --nodes 1 2 4 8 16 32 64 \
    --cases ~/WRF_benchmarks/cases/conus12km \
    --trial 1
wrf_run_pbs_jobs \
    --wrfs ~/work/WRFs/WRFV3.8.1-gnu6.3.0-mpt2.18 \
    --nodes 1 2 4 8 16 32 64 \
    --cases ~/WRF_benchmarks/cases/conus12km \
    --trial 1
wrf_run_pbs_jobs \
    --wrfs ~/work/WRFs/WRFV3.8.1-gnu6.3.0-mvapich2.2 \
    --nodes 1 2 4 8 16 32 64 \
    --cases ~/WRF_benchmarks/cases/conus12km \
    --trial 1
#+end_src

#+begin_src sh
wrf_run_pbs_jobs \
    --wrfs \
    ~/work/WRFs/WRFV3.9.1.1-intel-dmpar-mpt2.18 \
    ~/work/WRFs/WRFV3.8.1-intel-dmpar-mpt2.18 \
    ~/work/WRFs/WRFV3.9.1.1-intel-dmpar-mvapich2.2 \
    --nodes 2 4 8 16 32 64 128 256 512 \
    --cases \
    ~/WRF_benchmarks/cases/conus12km \
    ~/WRF_benchmarks/cases/conus2.5km \
    ~/WRF_benchmarks/cases/katrina1km \
    ~/WRF_benchmarks/cases/katrina3km \
    ~/WRF_benchmarks/cases/tracer_simple_01 \
    ~/WRF_benchmarks/cases/dust_simple_01 \
    --trial 1
#+end_src


** The benchmark cases
*** katrina (1km, 3km, 30km)
The Katrina data can be downloaded using curl from the WRF tutorial page

#+begin_src sh
curl http://www2.mmm.ucar.edu/wrf/TUTORIAL_DATA/Katrina.tar.gz -o Katrina.tar.gz
tar -xf Katrina.tar
#+end_src

To generate the necessary ~wrfbdy_d01~ and ~wrfinput_d01~ WRF input data for
~wrf_run_pbs_jobs~, one needs to run WPS on the above Katrina data. The
following script can used to do this. WPS must already be compiled. Note that
for the larger 1km and 3km domains, running a ~dmpar~ version of ~real.exe~ may
be necessary since the serial version by encounter a ~SIGSEGV~ from running out
of memory.

#+begin_src sh
#!/bin/sh
set -e
CASE_NAME=-ex
DATA_DIR=~/work/raw_data/Katrina
WPS_DIR=~/work/WPS

RUN_DIR=~/work/case_data/katrina$CASE_NAME
mkdir -p $RUN_DIR
cd $RUN_DIR

ln -sf ~/WRF_benchmarks/cases/katrina$CASE_NAME/namelist.* .
ln -sf $(readlink -f $WPS_DIR)/*.exe .
ln -sf $WPS_DIR/ungrib/Variable_Tables/Vtable.GFS Vtable
ln -sf ~/work/WRFs/WRFV3.9.1.1-intel-serial/main/real.exe .

$WPS_DIR/link_grib.csh $DATA_DIR/avn

./ungrib.exe >& ungrib_data.log
./geogrid.exe
./metgrid.exe
./real.exe
#+end_src

The ~cases~ directory has the namelists for a 1km and 3km resolution case as
well as the example namelist for a small run used in the tutorial at
[[http://www2.mmm.ucar.edu/wrf/OnLineTutorial/CASES/SingleDomain/index.html]]

*** conus (12km, 2.5km)
The ~wrfbdy_d01~ and ~wrfrst_d01~ files for the official CONUS benchmarks at
12km and 2.5km resolution can be found at:
[[http://www2.mmm.ucar.edu/wrf/WG2/benchv3/]]

*** ~dust_simple_01~ and ~tracer_simple_01~
These are wrf-chem cases
